## 概念

- 一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算
- RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和group by）而创建得到新的RDD
---
## 一般运行流程
RDD典型的执行过程如下：
- RDD读入外部数据源进行创建
- RDD经过一系列的转换（Transformation）操作，每一次都会产生不同的RDD，供给下一
个转换操作使用
- 最后一个RDD经过Action操作进行转换，并输出到外部数据存放位置
---
## RDD 的内部结构

RDD（Resilient Distributed Dataset）是 Spark 中的核心数据抽象，一个 RDD 并不仅是一组数据分区，它还携带了调度、容错和执行所需的全部元数据。本节介绍 RDD 的内部构成，为理解宽依赖、窄依赖、Shuffle、Stage 划分等内容打下基础。

RDD 是一个 Scala 抽象类，其内部包含以下关键组件：


### 1. 数据分区（Partitions）

创建RDD时，首先要读取数据文件，我们以读取hdfs文件为例来介绍，其他大同小异。
hdfs中的文件是以block为单位、分布式地存储在系统各个worker节点上的，创建RDD时，每个block会被读取为一个partition,读取到worker节点的内存。整个RDD是一个分布式的抽象概念，它的实际数据，按照这种方式分散在整个分布式系统的。

**Partitions 是 RDD 的最小并行计算单元**，每个分区对应一个数据片段，由不同节点上的 Task 并行处理。

特点：
- 每个 RDD 包含多个 partition（由 `def partitions: Array[Partition]` 定义）
- partition 本身不存数据，仅描述如何访问该数据切片
- 从 HDFS 读取时通常：**每个 HDFS block 对应一个 partition**
- partition 的数量决定 RDD 的并行度（即 Task 的数量）


### 2. 依赖关系与血缘（Dependencies / Lineage）

每个 RDD 都记录其父 RDD 的依赖关系：

```scala
def dependencies: Seq[Dependency[_]]
```

依赖用于描述 **DAG 中的边**，从而形成完整的逻辑执行图（lineage DAG）。

依赖类型包括：

- **窄依赖（NarrowDependency）**  
    子分区只依赖少量特定父分区，可进行流水线（Pipeline）计算
- **宽依赖（ShuffleDependency）**  
    子分区可能依赖所有父分区，需要进行 Shuffle 分发

依赖关系决定：

- 是否需要 Shuffle
- Stage 如何划分
- 容错时如何重算 partition（基于 lineage）

### 3. 计算逻辑（compute）

每个 RDD 都定义了如何计算一个分区的数据：

```scala
def compute(split: Partition, context: TaskContext): Iterator[T]
```

这是 Task 实际执行的函数。

- 窄依赖可以将多个 compute 串联成流水线（无需写磁盘）
- 宽依赖在 shuffle 边界必须中断 compute，写入 shuffle 文件

compute 决定了：
- pipeline 能否建立
- shuffle 边界的划分
- stage 内部的 task 行为

### 4. 数据本地性（preferredLocations）

```scala
def preferredLocations(split: Partition): Seq[String]
```

Spark 会根据此信息将 Task 尽量调度到数据所在节点，提高数据本地性。

常见来源：
- HDFS block 所在节点
- 缓存数据所在的 executor
- Shuffle 文件所在节点

本地性决定 Task 调度的最优策略，是 Stage 内 Task 分配的重要依据。

### 5. 分区器（Partitioner）

Partitioner 控制 Key-Value RDD 中 **key → partition** 的映射规则：
- HashPartitioner
- RangePartitioner

Partitioner 的作用：
- 决定 shuffle 的输出分布
- 决定后续操作是否需要再次 shuffle  
    （例如，reduceByKey 会设置 partitioner，使随后 mapValues 成为窄依赖）

只有 Key-Value RDD（如 `RDD[(K, V)]`）才可能携带 partitioner。

### 6. 存储级别与持久化（storageLevel）

RDD 的缓存行为由 storageLevel 指定：
- MEMORY_ONLY
- MEMORY_AND_DISK
- DISK_ONLY
- OFF_HEAP

缓存影响：
- 避免重复计算宽依赖链
- 改变任务的实际执行路径
- 可能改变 locality（缓存 block 具有新的位置）

storageLevel 是 Spark 容错与执行优化的一部分。

### 7. RDD 元数据（id、name）
- `id`: RDD 的唯一编号，便于调试
- `name`: 用户可自定义，用于 Spark UI 显示
- `scope`: 用于将多个操作归类展示

这些元数据不影响执行逻辑，但有助于调试与可视化。

### 8. 执行上下文（SparkContext）

每个 RDD 都携带其所属的 SparkContext，用于：
- 调度任务
- 管理缓存
- 提供 Shuffle 管理器
- 与 BlockManager 交互
- 提供序列化、广播等基础设施

SparkContext 是 RDD 访问集群资源的桥梁。

### 小结：RDD 的内部结构总览

| 组件                        | 作用                      |
| ------------------------- | ----------------------- |
| **Partitions**            | 决定并行度与数据切片              |
| **Dependencies（Lineage）** | 构成 DAG，决定是否需要 shuffle   |
| **compute()**             | 定义分区计算逻辑，是 pipeline 的基础 |
| **preferredLocations**    | 决定 task 调度的本地性          |
| **Partitioner**           | 控制 key 的分区方式，影响 shuffle |
| **storageLevel**          | 缓存与容错策略                 |
| **id / name**             | 元数据，便于调试                |
| **SparkContext**          | 访问调度器、存储系统和集群资源         |

这些内部组件共同支持了 Spark 的：
- 惰性计算（lazy evaluation）
- DAG 调度
- Shuffle 管理
- Stage 划分
- Pipeline 优化（窄依赖）
- Retry 容错（lineage 追踪）

---
## 宽依赖与窄依赖

一个RDD（父RDD）经过Transformation后得到一个新的RDD（子RDD）。子RDD对父RDD具有依赖关系，这个依赖关系可以按照所调用的Transformation算子类型划分为**宽依赖和窄依赖**

宽依赖和窄依赖的划分由Driver上的DAGScheduler在构建DAG时确定，DAGScheduler并不会到每一个节点上去扫描数据，它只会根据代码中Transformation的类型进行判断。而一种Transformation到底产生宽依赖还是窄依赖，取决于该操作产生的依赖关系是否与数据的具体值有关。

### 窄依赖
子partition只依赖父RDD的一个或少量几个**确定的**partition,则这种transformation产生窄依赖。

上述内容是课本中的定义，但很模糊，实际上宽依赖和窄依赖最本质的判断标准不是partition的数量，而是一个子partition依赖的所有父partition能否在**不查看partition内具体数据**的情况下确定下来。

**如果父 RDD 中任意一条数据最终进入哪个子 partition 完全由它所在的父 partition 的 partitionId 决定，而不依赖数据内容本身（如 key、值），那么这种依赖是窄依赖.**
### 宽依赖
子partition依赖多个甚至所有父partition，则为宽依赖。

实际上，定义应该描述为，**如果数据最终进入哪个子 partition 需要依据该条数据的内容（如 key）来决定，那么这种依赖是宽依赖。**


*一般情况下，窄依赖表现为一个子RDD分区以来一个或多个父RDD分区，宽依赖表现为一个父RDD的分区对应多个子RDD分区。
在绝大多数情况下，宽依赖会导致shuffle,而窄依赖不会导致shuffle
*

---

## shuffle操作

shuffle是数据重新分区的过程。
重新分区后的数据会被暂存到磁盘上然后通过网络发送到对应的分区，这是spark中最昂贵的操作。

 Shuffle的典型操作：
- **`groupByKey`**：根据key进行分组，涉及到不同分区之间的数据交换。
- **`reduceByKey`**：通过key聚合数据，需要将相同key的数据分配到同一分区。
- **`join`**：两个RDD根据key进行连接，可能会涉及跨分区、跨节点的数据交换。
- **`distinct`**：去重操作需要将所有数据拉取到一个地方进行去重。

___
## stage（阶段）划分

spark把一整个作业划分成多个阶段(stage),以shuffle为间隔，宽依赖和窄依赖是划分stage的依据，每过一个shuffle就划分出一个stage。

每个RDD操作都是一个fork/join，把操作的计算指令发送（fork）到每个RDD分区，在分区上完成计算后进行结果的join,如果join时需要不同分区之间数据的重新划分，即shuffle,那么就会划分一个新的stage,否则不划分新stage. 

不需要shuffle的操作即窄依赖操作，一个分区在完成当前fork/join后可以直接执行下一个RDD操作，即同一个stage的多个RDD操作可以流水线式作业，不需要等待其他分区，而需要shuffle的操作则需要阻塞该操作的各个Task进行shuffle阶段的数据重新分区。[[1.基本概念与架构设计#Stage]]


## RDD运行流程总结
- 创建RDD对象；
- SparkContext负责计算RDD之间的依赖关系，构建DAG；
- DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执行。