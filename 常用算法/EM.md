**EM 算法**是一种用于含有隐变量的概率模型的最大似然估计（MLE）方法。它的核心思想是通过交替进行 **E 步（期望步）** 和 **M 步（最大化步）** 来推导出参数的最优估计。

## EM 算法的基本概述

假设我们有一个包含观测数据 $X$ 和隐变量 $Z$ 的模型，目标是对模型参数 $\theta$ 进行极大似然估计。EM 算法的目标是最大化观测数据的对数似然函数：

$$
\log P(X \mid \theta) = \sum_{i=1}^{n} \log P(x_i \mid \theta)
$$

但是，由于隐变量 $Z$ 的存在，我们无法直接计算对数似然。EM 算法通过引入隐变量的后验分布来迭代优化 $\theta$。

## EM 算法的流程

EM 算法通过 **E 步** 和 **M 步** 来进行迭代优化，直到参数收敛。

### E 步（Expectation Step）

E 步的目标是计算在给定观测数据 $X$ 和当前参数 $\theta^{(t)}$ 下，隐变量 $Z$ 的后验分布 $P(Z \mid X, \theta^{(t)})$，并计算期望统计量。

首先，我们使用 **贝叶斯公式** 来计算后验分布：

$$
P(Z \mid X, \theta^{(t)}) = \frac{P(X, Z \mid \theta^{(t)})}{P(X \mid \theta^{(t)})}
$$

在 GMM（高斯混合模型）中，$P(X, Z \mid \theta^{(t)})$ 表示数据点和隐变量的联合分布，$P(X \mid \theta^{(t)})$ 是边际似然。

E 步的核心是计算 Q 函数：

$$
Q(\theta \mid \theta^{(t)}) = \mathbb{E}_{Z \mid X, \theta^{(t)}} \left[ \log P(X, Z \mid \theta) \right]
$$

Q 函数的计算需要用到隐变量的后验分布，并对联合分布进行期望计算。

### M 步（Maximization Step）

M 步的目标是最大化 Q 函数，从而更新参数 $\theta$：

$$
\theta^{(t+1)} = \arg \max_{\theta} Q(\theta \mid \theta^{(t)})
$$

M 步的本质是通过隐变量的期望来计算新的参数估计。

## GMM 模型的 EM 求解

在高斯混合模型（GMM）中，假设数据来自于 \(K\) 个高斯分布的混合，每个高斯分布有对应的均值、协方差矩阵和权重。EM 算法用于从数据中估计这些参数。

### 1. GMM 模型假设

- 观测数据 $x_i$ 来自于 $K$ 个高斯分布，每个分布的权重为 $\pi_k$。
- 数据的每个样本 $x_i$ 对应于一个隐变量 $z_i$，表示该样本属于哪一个高斯分布。

### 2. E 步：计算责任度

在 E 步中，我们计算每个数据点 $x_i$ 属于各个高斯分布的**责任度** $\gamma_{ik}$，即样本 $x_i$ 属于第 $k$ 个高斯分布的概率。

使用贝叶斯公式计算后验概率（责任度）：
$$
\gamma_{ik} = P(z_i = k \mid x_i, \theta^{(t)}) = \frac{\pi_k^{(t)} \mathcal{N}(x_i \mid \mu_k^{(t)}, \Sigma_k^{(t)})}{\sum_{j=1}^{K} \pi_j^{(t)} \mathcal{N}(x_i \mid \mu_j^{(t)}, \Sigma_j^{(t)})}
$$
其中：

- $\pi_k^{(t)}$：第 $k$ 个高斯分布的权重
- $\mu_k^{(t)}$ 和 $\Sigma_k^{(t)}$：第 $k$ 个高斯分布的均值和协方差矩阵
- $\mathcal{N}(x_i \mid \mu_k^{(t)}, \Sigma_k^{(t)})$：第 $k$ 个高斯分布下，样本 $x_i$ 的概率密度函数

### 3. M 步：最大化 Q 函数

在 M 步中，我们使用 E 步计算得到的责任度来更新模型的参数。
记$N_k=\sum_i^n\gamma_{ik},N=\text{总样本量}$

- **更新权重**：
$$
\pi_k^{(t+1)} = \frac{N_k^{(t+1)}}{N}
$$
其中：
$$
N_k^{(t+1)} = \sum_{i=1}^n \gamma_{ik}
$$

- **更新均值**：
$$
\mu_k^{(t+1)} = \frac{1}{N_k^{(t+1)}} \sum_{i=1}^n \gamma_{ik} x_i
$$

- **更新协方差矩阵**：
$$
\Sigma_k^{(t+1)} = \frac{1}{N_k^{(t+1)}} \sum_{i=1}^n \gamma_{ik} (x_i - \mu_k^{(t+1)})(x_i - \mu_k^{(t+1)})^T
$$

### 4. E 步和 M 步的迭代

通过 **E 步** 和 **M 步** 的交替进行，EM 算法不断更新参数 $\pi_k$, $\mu_k$, 和 $\Sigma_k$，直到对数似然收敛。

- **E 步**：计算每个样本属于每个高斯分布的责任度 $\gamma_{ik}$。
- **M 步**：根据责任度更新高斯分布的参数（权重、均值、协方差）。

通过多次迭代，EM 算法会收敛到最大化观测数据对数似然的参数估计。

